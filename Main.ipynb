import requests
import json
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# set up the YouTube API parameters
video_id = input("Enter YouTube video ID: ")
api_key = "AIzaSyBUGGWZ_EZtW__4IoUIPrPvcTcKRiDva4k"
url = f"https://www.googleapis.com/youtube/v3/commentThreads?key={api_key}&textFormat=plainText&part=snippet&videoId={video_id}&maxResults=100"

# send a request to the YouTube API and get the response
response = requests.get(url)
data = json.loads(response.text)

# extract the comments from the response
comments = []
for item in data["items"]:
    comment = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
    comment = re.sub(r"http\S+", "", comment) # remove URLs from the comments
    comments.append(comment)

# perform sentiment analysis on the comments
sia = SentimentIntensityAnalyzer()
sentiments = []
for comment in comments:
    sentiment = sia.polarity_scores(comment)
    sentiments.append(sentiment)

# create a word cloud based on the sentiments
words = []
for sentiment in sentiments:
    if sentiment["compound"] >= 0.05:
        words += ["good", "great", "excellent", "positive"]
    elif sentiment["compound"] <= -0.05:
        words += ["bad", "terrible", "horrible", "negative"]
    else:
        words += ["neutral"]
        
wordcloud = WordCloud(width=800, height=800, background_color="white").generate(" ".join(words))
plt.figure(figsize=(8,8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
